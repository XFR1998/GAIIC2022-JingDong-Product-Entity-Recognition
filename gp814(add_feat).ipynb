{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from ark_nlp.model.ner.global_pointer_bert import Tokenizer\n",
    "from ark_nlp.model.ner.global_pointer_bert import Dataset as Dt\n",
    "import os\n",
    "import jieba\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import logging\n",
    "from nezha import NeZhaConfig, NeZhaModel, NeZhaForMaskedLM\n",
    "from make_feature.extract_word_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机种子： 1998\n",
      "batch_size:  8\n",
      "./my_nezha_cn_base2/\n",
      "训练集大小： 9\n",
      "验证集大小： 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./my_nezha_cn_base2/ were not used when initializing NeZhaModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing NeZhaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NeZhaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ./my_nezha_cn_base2/ and are newly initialized: ['bert.encoder.layer.3.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.5.attention.self.relative_positions_encoding.positions_encoding', 'bert.pooler.dense.bias', 'bert.encoder.layer.7.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.0.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.6.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.9.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.2.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.4.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.1.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.10.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.11.attention.self.relative_positions_encoding.positions_encoding', 'bert.pooler.dense.weight', 'bert.encoder.layer.8.attention.self.relative_positions_encoding.positions_encoding']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # GPU\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 禁止hash随机化\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # True的话会自动寻找最适合当前配置的高效算法，来达到优化运行效率的问题。False保证实验结果可复现\n",
    "\n",
    "# 设置随机数种子\n",
    "RANDOM_SEED = 1998\n",
    "print('随机种子：', RANDOM_SEED)\n",
    "setup_seed(RANDOM_SEED)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "dropout_num = 0\n",
    "start = time.time()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LEN = 128\n",
    "batch_size = 8\n",
    "print('batch_size: ', batch_size)\n",
    "EPOCHS = 6\n",
    "LR = 2e-5\n",
    "early_stop_epochs = 2\n",
    "model_path = './my_nezha_cn_base2/'\n",
    "\n",
    "print(model_path)\n",
    "\n",
    "\n",
    "\n",
    "config = NeZhaConfig.from_json_file(model_path + 'config.json')\n",
    "config.num_labels = 53\n",
    "config.output_hidden_states=True\n",
    "# encoder = NeZhaForSequenceClassification(config)\n",
    "encoder = NeZhaModel.from_pretrained(model_path, config=config)\n",
    "\n",
    "import os\n",
    "from ark_nlp.factory.utils.conlleval import get_entity_bio\n",
    "\n",
    "datalist = []\n",
    "with open('./datasets/preliminary_contest_datasets/train_data/train.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    lines.append('\\n')\n",
    "\n",
    "    text = []\n",
    "    labels = []\n",
    "    label_set = set()\n",
    "\n",
    "    for line in lines:\n",
    "        if line == '\\n':\n",
    "            text = ''.join(text)\n",
    "            entity_labels = []\n",
    "            for _type, _start_idx, _end_idx in get_entity_bio(labels, id2label=None):\n",
    "                entity_labels.append({\n",
    "                    'start_idx': _start_idx,\n",
    "                    'end_idx': _end_idx,\n",
    "                    'type': _type,\n",
    "                    'entity': text[_start_idx: _end_idx + 1]\n",
    "                })\n",
    "\n",
    "            if text == '':\n",
    "                continue\n",
    "\n",
    "            datalist.append({\n",
    "                'text': text,\n",
    "                'label': entity_labels,\n",
    "                'BIO': labels\n",
    "            })\n",
    "\n",
    "            text = []\n",
    "            labels = []\n",
    "\n",
    "        elif line == '  O\\n':\n",
    "            text.append(' ')\n",
    "            labels.append('O')\n",
    "        else:\n",
    "            line = line.strip('\\n').split()\n",
    "            if len(line) == 1:\n",
    "                term = ' '\n",
    "                label = line[0]\n",
    "            else:\n",
    "                term, label = line\n",
    "            text.append(term)\n",
    "            label_set.add(label.split('-')[-1])\n",
    "            labels.append(label)\n",
    "\n",
    "# 这里随意分割了一下看指标，建议实际使用sklearn分割或者交叉验证\n",
    "#datalist =  datalist[:10000]\n",
    "# train_data_df = pd.DataFrame(datalist)\n",
    "# print('训练集大小：', len(train_data_df))\n",
    "# train_data_df['label'] = train_data_df['label'].apply(lambda x: str(x))\n",
    "#\n",
    "# dev_data_df = pd.DataFrame(datalist[-400:])\n",
    "# dev_data_df['label'] = dev_data_df['label'].apply(lambda x: str(x))\n",
    "\n",
    "all_data = pd.DataFrame(datalist)\n",
    "all_data = all_data[:10]\n",
    "\n",
    "train_data_df, dev_data_df = train_test_split(all_data, test_size = 0.1, random_state=RANDOM_SEED)\n",
    "train_data_df.index = list(range(len(train_data_df)))\n",
    "dev_data_df.index = list(range(len(dev_data_df)))\n",
    "train_data_df['label'] = train_data_df['label'].apply(lambda x: str(x))\n",
    "dev_data_df['label'] = dev_data_df['label'].apply(lambda x: str(x))\n",
    "\n",
    "print('训练集大小：', len(train_data_df))\n",
    "print('验证集大小：', len(dev_data_df))\n",
    "\n",
    "label_list = sorted(list(label_set))\n",
    "del text\n",
    "del label_set\n",
    "del labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "train_dataset = Dt(train_data_df, categories=label_list)\n",
    "dev_dataset = Dt(dev_data_df, categories=label_list)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "ark_tokenizer = Tokenizer(vocab=tokenizer, max_seq_len=128)\n",
    "\n",
    "train_dataset.convert_to_ids(ark_tokenizer)\n",
    "dev_dataset.convert_to_ids(ark_tokenizer)\n",
    "\n",
    "\n",
    "Ent2id = train_dataset.cat2id  # 53\n",
    "id2Ent = train_dataset.id2cat\n",
    "\n",
    "pinyin_dict = pd.read_pickle('./make_feature/feature_dict/word_pinyin_dict.pkl')\n",
    "Pinyin_dict_len = len(pinyin_dict)\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, ark_data):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.ark_data = ark_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        token_ids, at_mask, pinyin_ids = self.get_token_ids(row)\n",
    "        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(at_mask, dtype=torch.long), \\\n",
    "               torch.tensor(self.ark_data[index]['label_ids'].to_dense()), torch.tensor(self.ark_data[index]['token_type_ids'],dtype=torch.long), \\\n",
    "                torch.tensor(pinyin_ids)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def return_pinyin_ids(self, x):\n",
    "        pinyin_list = extract_pinyin(x, MAX_LEN)\n",
    "        pinyin_ids = [pinyin_dict[i] if i in pinyin_dict.keys() else pinyin_dict['<UNK>'] for i in pinyin_list]\n",
    "        return pinyin_ids\n",
    "\n",
    "\n",
    "    def get_token_ids(self, row):\n",
    "        sentence = row.text\n",
    "        pinyin_ids = self.return_pinyin_ids(sentence)\n",
    "        tokens = self.tokenizer.tokenize(sentence)\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        padding = [0] * (self.max_len - len(tokens))\n",
    "        at_mask = [1] * len(tokens)\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        token_ids = token_ids + padding\n",
    "        at_mask = at_mask + padding\n",
    "        return token_ids, at_mask, pinyin_ids\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        token_ids = torch.stack([x[0] for x in batch])\n",
    "        at_mask = torch.stack([x[1] for x in batch])\n",
    "        labels = torch.stack([x[2] for x in batch])\n",
    "        token_type_ids = torch.stack([x[3] for x in batch])\n",
    "        pinyin_ids = torch.stack([x[4] for x in batch])\n",
    "        return token_ids, at_mask, labels.squeeze(), token_type_ids, pinyin_ids\n",
    "\n",
    "\n",
    "ner_train_dataset = Dataset(train_data_df, ark_tokenizer, MAX_LEN, train_dataset)\n",
    "ner_dev_dataset = Dataset(dev_data_df, ark_tokenizer, MAX_LEN, dev_dataset)\n",
    "\n",
    "train_loader = DataLoader(ner_train_dataset,  # 1250\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=ner_train_dataset.collate_fn)\n",
    "dev_loader = DataLoader(ner_dev_dataset,  # 13\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=ner_dev_dataset.collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_15000/3695479307.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mrow\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "# row\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# for sample in train_loader:\n",
    "#     break\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# x = sample[0][2]\n",
    "# x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# [tokenizer.ids_to_tokens[int(i.numpy())] for i in x]\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# i2p = {}\n",
    "# for k, v in word_pinyin_dict.items():\n",
    "#     i2p[v]=k\n",
    "# x = sample[4][2]\n",
    "# [i2p[int(i.numpy())] for i in x]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(101)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "class FGM(object):\n",
    "    def __init__(self, module):\n",
    "        self.module = module\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(\n",
    "            self,\n",
    "            epsilon=1.,\n",
    "            emb_name='word_embeddings'\n",
    "    ):\n",
    "        for name, param in self.module.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(\n",
    "            self,\n",
    "            emb_name='word_embeddings'\n",
    "    ):\n",
    "        for name, param in self.module.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "\n",
    "class PGD():\n",
    "    def __init__(self, model, emb_name='word_embeddings', epsilon=1., alpha=0.3):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        self.model = model\n",
    "        self.emb_name = emb_name\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.emb_backup = {}\n",
    "        self.grad_backup = {}\n",
    "\n",
    "    def attack(self, is_first_attack=False):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and self.emb_name in name:\n",
    "                if is_first_attack:\n",
    "                    self.emb_backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0:\n",
    "                    r_at = self.alpha * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = self.project(name, param.data, self.epsilon)\n",
    "\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and self.emb_name in name:\n",
    "                assert name in self.emb_backup\n",
    "                param.data = self.emb_backup[name]\n",
    "        self.emb_backup = {}\n",
    "\n",
    "    def project(self, param_name, param_data, epsilon):\n",
    "        r = param_data - self.emb_backup[param_name]\n",
    "        if torch.norm(r) > epsilon:\n",
    "            r = epsilon * r / torch.norm(r)\n",
    "        return self.emb_backup[param_name] + r\n",
    "\n",
    "    def backup_grad(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                self.grad_backup[name] = param.grad.clone()\n",
    "\n",
    "    def restore_grad(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                param.grad = self.grad_backup[name]\n",
    "\n",
    "\n",
    "class EMA():\n",
    "    def __init__(self, model, decay):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "\n",
    "    def register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                self.backup[name] = param.data\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "\n",
    "class GlobalPointerCrossEntropy(nn.Module):\n",
    "    '''Multi-class Focal loss implementation'''\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(GlobalPointerCrossEntropy, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def multilabel_categorical_crossentropy(y_true, y_pred):\n",
    "        y_pred = (1 - 2 * y_true) * y_pred\n",
    "        y_pred_neg = y_pred - y_true * 1e12\n",
    "        y_pred_pos = y_pred - (1 - y_true) * 1e12\n",
    "        zeros = torch.zeros_like(y_pred[..., :1])\n",
    "        y_pred_neg = torch.cat([y_pred_neg, zeros], dim=-1)\n",
    "        y_pred_pos = torch.cat([y_pred_pos, zeros], dim=-1)\n",
    "        neg_loss = torch.logsumexp(y_pred_neg, dim=-1)\n",
    "        pos_loss = torch.logsumexp(y_pred_pos, dim=-1)\n",
    "\n",
    "        return neg_loss + pos_loss\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        logits: [N, C, L, L]\n",
    "        \"\"\"\n",
    "        bh = logits.shape[0] * logits.shape[1]\n",
    "        target = torch.reshape(target, (bh, -1))\n",
    "        logits = torch.reshape(logits, (bh, -1))\n",
    "        return torch.mean(GlobalPointerCrossEntropy.multilabel_categorical_crossentropy(target, logits))\n",
    "\n",
    "\n",
    "class MetricsCalculator(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def get_sample_f1(self, y_pred, y_true):\n",
    "        y_pred = torch.gt(y_pred, 0).float()\n",
    "        return 2 * torch.sum(y_true * y_pred) / torch.sum(y_true + y_pred)\n",
    "\n",
    "    def get_sample_precision(self, y_pred, y_true):\n",
    "        y_pred = torch.gt(y_pred, 0).float()\n",
    "        return torch.sum(y_pred[y_true == 1]) / (y_pred.sum() + 1)\n",
    "\n",
    "    def get_evaluate_fpr(self, y_pred, y_true):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        pred = []\n",
    "        true = []\n",
    "        for b, l, start, end in zip(*np.where(y_pred > 0)):\n",
    "            pred.append((b, l, start, end))\n",
    "        for b, l, start, end in zip(*np.where(y_true > 0)):\n",
    "            true.append((b, l, start, end))\n",
    "\n",
    "        R = set(pred)\n",
    "        T = set(true)\n",
    "        X = len(R & T)\n",
    "        Y = len(R)\n",
    "        Z = len(T)\n",
    "        if Y != 0:\n",
    "            f1, precision, recall = 2 * X / (Y + Z), X / Y, X / Z\n",
    "        else:\n",
    "            f1, precision, recall = 2 * X / (Y + Z), 0, X / Z\n",
    "        return f1, precision, recall\n",
    "\n",
    "\n",
    "class GlobalPointer(nn.Module):\n",
    "    def __init__(self, encoder, ent_type_size, inner_dim, RoPE=True):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.ent_type_size = ent_type_size\n",
    "        self.inner_dim = inner_dim\n",
    "        self.hidden_size = encoder.config.hidden_size\n",
    "        self.dense = nn.Linear(self.hidden_size*2, self.ent_type_size * self.inner_dim * 2)\n",
    "        self.lstm = nn.LSTM(input_size=768,\n",
    "                          hidden_size=384,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "        # self.radical_embedding = nn.Embedding(Radical_dict_len, 768)\n",
    "        self.pinyin_embedding = nn.Embedding(Pinyin_dict_len, 768)\n",
    "\n",
    "        self.RoPE = RoPE\n",
    "\n",
    "    def sinusoidal_position_embedding(self, batch_size, seq_len, output_dim):\n",
    "        position_ids = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(-1)\n",
    "\n",
    "        indices = torch.arange(0, output_dim // 2, dtype=torch.float)\n",
    "        indices = torch.pow(10000, -2 * indices / output_dim)\n",
    "        embeddings = position_ids * indices\n",
    "        embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)\n",
    "        embeddings = embeddings.repeat((batch_size, *([1] * len(embeddings.shape))))\n",
    "        embeddings = torch.reshape(embeddings, (batch_size, seq_len, output_dim))\n",
    "        embeddings = embeddings.to(self.device)\n",
    "        return embeddings\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, pinyin_ids):\n",
    "        self.device = input_ids.device\n",
    "\n",
    "        context_outputs = self.encoder(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        last_hidden_state = context_outputs[0]\n",
    "        # last_hidden_state.shape = (bs, seq_len, 768)\n",
    "\n",
    "        emb_hidden_state = context_outputs[2][0]\n",
    "\n",
    "        batch_size = last_hidden_state.size()[0]\n",
    "        seq_len = last_hidden_state.size()[1]\n",
    "\n",
    "\n",
    "\n",
    "        # 特征融合\n",
    "        # radical_feat = self.radical_embedding(radical_ids)\n",
    "        pinyin_feat = self.pinyin_embedding(pinyin_ids)\n",
    "\n",
    "        feats = emb_hidden_state+pinyin_feat\n",
    "\n",
    "        h_0 = torch.randn(2, batch_size, 384).to(device)\n",
    "        c_0 = torch.randn(2, batch_size, 384).to(device)\n",
    "        feats,(_,_)= self.lstm(feats, (h_0,c_0))\n",
    "        last_hidden_state = torch.cat((last_hidden_state, feats), dim=-1)\n",
    "        # outputs:(batch_size, seq_len, ent_type_size*inner_dim*2)\n",
    "        outputs = self.dense(last_hidden_state)\n",
    "        outputs = torch.split(outputs, self.inner_dim * 2, dim=-1)\n",
    "        # outputs:(batch_size, seq_len, ent_type_size, inner_dim*2)\n",
    "        outputs = torch.stack(outputs, dim=-2)\n",
    "        # qw,kw:(batch_size, seq_len, ent_type_size, inner_dim)\n",
    "        qw, kw = outputs[..., :self.inner_dim], outputs[..., self.inner_dim:]  # TODO:修改为Linear获取？\n",
    "\n",
    "        if self.RoPE:\n",
    "            # pos_emb:(batch_size, seq_len, inner_dim)\n",
    "            pos_emb = self.sinusoidal_position_embedding(batch_size, seq_len, self.inner_dim)\n",
    "            # cos_pos,sin_pos: (batch_size, seq_len, 1, inner_dim)\n",
    "            cos_pos = pos_emb[..., None, 1::2].repeat_interleave(2, dim=-1)\n",
    "            sin_pos = pos_emb[..., None, ::2].repeat_interleave(2, dim=-1)\n",
    "            qw2 = torch.stack([-qw[..., 1::2], qw[..., ::2]], -1)\n",
    "            qw2 = qw2.reshape(qw.shape)\n",
    "            qw = qw * cos_pos + qw2 * sin_pos\n",
    "            kw2 = torch.stack([-kw[..., 1::2], kw[..., ::2]], -1)\n",
    "            kw2 = kw2.reshape(kw.shape)\n",
    "            kw = kw * cos_pos + kw2 * sin_pos\n",
    "\n",
    "        # logits:(batch_size, ent_type_size, seq_len, seq_len)\n",
    "        logits = torch.einsum('bmhd,bnhd->bhmn', qw, kw)\n",
    "\n",
    "        # padding mask\n",
    "        pad_mask = attention_mask.unsqueeze(1).unsqueeze(1).expand(batch_size, self.ent_type_size, seq_len, seq_len)\n",
    "        # pad_mask_h = attention_mask.unsqueeze(1).unsqueeze(-1).expand(batch_size, self.ent_type_size, seq_len, seq_len)\n",
    "        # pad_mask = pad_mask_v&pad_mask_h\n",
    "        logits = logits * pad_mask - (1 - pad_mask) * 1e12\n",
    "\n",
    "        # 排除下三角\n",
    "        mask = torch.tril(torch.ones_like(logits), -1)\n",
    "        logits = logits - mask * 1e12\n",
    "\n",
    "        return logits / self.inner_dim ** 0.5\n",
    "\n",
    "\n",
    "model = GlobalPointer(encoder, len(Ent2id), 64)  # (encoder, ent_type_size, inner_dim)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bf22eae16744985925b1e75e970150c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 4.04 GiB already allocated; 0 bytes free; 4.16 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_15000/361616217.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[0mema\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mregister\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[0mmetrics\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMetricsCalculator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 116\u001B[1;33m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdev_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mearly_stop_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mearly_stop_epochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    117\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_15000/361616217.py\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, dev_loader, model_save_path, early_stop_epochs, is_fgm, is_pgd)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtoken_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mat_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpinyin_ids\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbar\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m             \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtoken_id\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mat_mask\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpinyin_ids\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel_id\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mtotal_loss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\MACHEN~1\\AppData\\Local\\Temp/ipykernel_15000/765248938.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, pinyin_ids)\u001B[0m\n\u001B[0;32m    203\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput_ids\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 205\u001B[1;33m         \u001B[0mcontext_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    206\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[0mlast_hidden_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcontext_outputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\打工\\竞赛\\GAIIC\\nezha.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001B[0m\n\u001B[0;32m    675\u001B[0m             \u001B[0mhead_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    676\u001B[0m             \u001B[0mencoder_hidden_states\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencoder_hidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 677\u001B[1;33m             \u001B[0mencoder_attention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencoder_extended_attention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    678\u001B[0m         )\n\u001B[0;32m    679\u001B[0m         \u001B[0msequence_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mencoder_outputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\打工\\竞赛\\GAIIC\\nezha.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001B[0m\n\u001B[0;32m    504\u001B[0m                 \u001B[0mall_hidden_states\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mall_hidden_states\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    505\u001B[0m             layer_outputs = layer_module(\n\u001B[1;32m--> 506\u001B[1;33m                 \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhead_mask\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoder_hidden_states\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoder_attention_mask\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    507\u001B[0m             )\n\u001B[0;32m    508\u001B[0m             \u001B[0mhidden_states\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayer_outputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\打工\\竞赛\\GAIIC\\nezha.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001B[0m\n\u001B[0;32m    466\u001B[0m             \u001B[0mencoder_attention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    467\u001B[0m     ):\n\u001B[1;32m--> 468\u001B[1;33m         \u001B[0mself_attention_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattention\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhead_mask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    469\u001B[0m         \u001B[0mattention_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself_attention_outputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    470\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself_attention_outputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# add self attentions if we output attention weights\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\打工\\竞赛\\GAIIC\\nezha.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001B[0m\n\u001B[0;32m    441\u001B[0m     ):\n\u001B[0;32m    442\u001B[0m         self_outputs = self.self(\n\u001B[1;32m--> 443\u001B[1;33m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhead_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoder_hidden_states\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoder_attention_mask\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    444\u001B[0m         )\n\u001B[0;32m    445\u001B[0m         \u001B[0mattention_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself_outputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden_states\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\打工\\竞赛\\GAIIC\\nezha.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001B[0m\n\u001B[0;32m    377\u001B[0m         \u001B[1;31m# This is actually dropping out entire tokens to attend to, which might\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    378\u001B[0m         \u001B[1;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 379\u001B[1;33m         \u001B[0mattention_probs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mattention_probs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    380\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    381\u001B[0m         \u001B[1;31m# Mask heads if we want to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     57\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 58\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minplace\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     59\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\ML_ENVS\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mdropout\u001B[1;34m(input, p, training, inplace)\u001B[0m\n\u001B[0;32m   1166\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mp\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0.0\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mp\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1.0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1167\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"dropout probability has to be between 0 and 1, \"\u001B[0m \u001B[1;34m\"but got {}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1168\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_VF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0minplace\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0m_VF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1169\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1170\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 4.04 GiB already allocated; 0 bytes free; 4.16 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "def global_pointer_f1_score(y_true, y_pred):\n",
    "    y_pred = torch.gt(y_pred, 0)\n",
    "    return torch.sum(y_true * y_pred).item(), torch.sum(y_true + y_pred).item()\n",
    "\n",
    "\n",
    "def validation_fn(model, dev_loader, loss_fn):\n",
    "    model.eval()\n",
    "    ema.apply_shadow()\n",
    "    total_loss = []\n",
    "    cnt = 0\n",
    "    total_f1_, total_precision_, total_recall_ = 0., 0., 0.\n",
    "    with torch.no_grad():\n",
    "        for token_id, at_mask, label_id, token_type_ids, pinyin_ids in dev_loader:\n",
    "            outputs = model(token_id.to(device), at_mask.to(device), token_type_ids.to(device), pinyin_ids.to(device))\n",
    "            loss = loss_fn(outputs, label_id.to(device))\n",
    "            total_loss.append(loss.item())\n",
    "            cnt += 1\n",
    "            f1, p, r = metrics.get_evaluate_fpr(outputs, label_id.to(device))\n",
    "            total_f1_ += f1\n",
    "            total_precision_ += p\n",
    "            total_recall_ += r\n",
    "        avg_f1 = total_f1_ / cnt\n",
    "        avg_precision = total_precision_ / cnt\n",
    "        avg_recall = total_recall_ / cnt\n",
    "        # t_loss = np.array(total_loss).mean()\n",
    "    # ema.restore()\n",
    "    return avg_f1, avg_precision, avg_recall\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, dev_loader, model_save_path='../outputs',\n",
    "                early_stop_epochs=2, is_fgm=True, is_pgd=False):\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    ########优化器 学习率\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "\n",
    "    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=LR, eps=1e-8)\n",
    "\n",
    "    loss_fn = GlobalPointerCrossEntropy().to(device)\n",
    "    best_vmetric = 0\n",
    "    if is_fgm:\n",
    "        fgm = FGM(module=model)\n",
    "\n",
    "    if is_pgd:\n",
    "        pgd = PGD(model=model)\n",
    "        K = 3\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = []\n",
    "        total_f1 = []\n",
    "        model.train()\n",
    "        bar = tqdm_notebook(train_loader)\n",
    "\n",
    "        for idx, (token_id, at_mask, label_id, token_type_ids, pinyin_ids) in enumerate(bar):\n",
    "            outputs = model(token_id.to(device), at_mask.to(device), token_type_ids.to(device), pinyin_ids.to(device))\n",
    "            loss = loss_fn(outputs, label_id.to(device))\n",
    "            total_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "            if is_fgm:\n",
    "                fgm.attack()\n",
    "                outputs = model(token_id.to(device), at_mask.to(device), token_type_ids.to(device), pinyin_ids.to(device))\n",
    "                loss_fgm = loss_fn(outputs, label_id.to(device))\n",
    "                loss_fgm.backward()\n",
    "                fgm.restore()\n",
    "            if is_pgd:\n",
    "                pgd.backup_grad()\n",
    "                for t in range(K):\n",
    "                    pgd.attack(is_first_attack=(t == 0))\n",
    "                    if t != K - 1:\n",
    "                        model.zero_grad()\n",
    "                    else:\n",
    "                        pgd.restore_grad()\n",
    "                    outputs = model(token_id.to(device), at_mask.to(device), token_type_ids.to(device), pinyin_ids.to(device))\n",
    "                    loss_pgd = loss_fn(outputs, label_id.to(device))\n",
    "                    loss_pgd.backward()\n",
    "                pgd.restore()\n",
    "            f1 = metrics.get_sample_f1(outputs, label_id.to(device))\n",
    "            total_f1.append(f1.item())\n",
    "            if ((idx + 1) % 4) == 0:\n",
    "                # optimizer the net\n",
    "                optimizer.step()  # update parameters of net\n",
    "                # ema.update()\n",
    "                optimizer.zero_grad()  # reset gradient\n",
    "                ema.update()\n",
    "        ema.apply_shadow()\n",
    "        t_loss = np.array(total_loss).mean()\n",
    "        t_f1 = np.array(total_f1).mean()\n",
    "        avg_f1, avg_precision, avg_recall = validation_fn(model, dev_loader, loss_fn)\n",
    "        print('epoch:{},训练集损失t_loss:{:.6f},准确率pre:{:.6f},召回率:{:.6f},F1_eval:{:.6f}'.format(epoch, t_loss,\n",
    "                                                                                           avg_precision, avg_recall,\n",
    "                                                                                           avg_f1))\n",
    "\n",
    "        model_save_path = 'model/nezha_train_model.bin'\n",
    "        if avg_f1 > best_vmetric:\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            best_vmetric = avg_f1\n",
    "            no_improve = 0\n",
    "            print('improve save model!!!')\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "\n",
    "        if no_improve_epochs == early_stop_epochs:\n",
    "            print('no improve score !!! stop train !!!')\n",
    "            break\n",
    "        ema.restore()\n",
    "\n",
    "\n",
    "ema = EMA(model, 0.995)\n",
    "ema.register()\n",
    "metrics = MetricsCalculator()\n",
    "train_model(model, train_loader, dev_loader, early_stop_epochs=early_stop_epochs)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}